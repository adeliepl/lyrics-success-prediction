{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d3360c4-b182-45a2-ae13-72969ff159a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0299ce4-c1d7-47f8-a123-07e46f63c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Hit_2.csv\")\n",
    "df.drop(columns = df.columns[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dd6a48f-9281-4693-93d5-9dae5b64a2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SongID</th>\n",
       "      <th>Song_x</th>\n",
       "      <th>Performer_x</th>\n",
       "      <th>Lyrics_x</th>\n",
       "      <th>Hit_x</th>\n",
       "      <th>Cleaned_Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'65 Love AffairPaul Davis</td>\n",
       "      <td>'65 Love Affair</td>\n",
       "      <td>Paul Davis</td>\n",
       "      <td>I was a car hop\\rYou were into be-bop\\rYou san...</td>\n",
       "      <td>False</td>\n",
       "      <td>car hop bebop sang wop diddy wop diddy wop doo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Til My Baby Comes HomeLuther Vandross</td>\n",
       "      <td>'Til My Baby Comes Home</td>\n",
       "      <td>Luther Vandross</td>\n",
       "      <td>Theres a whole lot of girls\\r\\nmessin around\\r...</td>\n",
       "      <td>False</td>\n",
       "      <td>whole lot girls messin around trying get thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Til Summer Comes AroundKeith Urban</td>\n",
       "      <td>'Til Summer Comes Around</td>\n",
       "      <td>Keith Urban</td>\n",
       "      <td>Another long summer's come and gone\\r\\nI don't...</td>\n",
       "      <td>False</td>\n",
       "      <td>another long summer 's come gone know always e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Til You Do Me RightAfter 7</td>\n",
       "      <td>'Til You Do Me Right</td>\n",
       "      <td>After 7</td>\n",
       "      <td>I was in love with you\\r\\nAnd gave my heart to...</td>\n",
       "      <td>False</td>\n",
       "      <td>love gave heart best keep satisfied took love ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'TilThe Angels</td>\n",
       "      <td>'Til</td>\n",
       "      <td>The Angels</td>\n",
       "      <td>Due to copyright restrictions, we are not auth...</td>\n",
       "      <td>False</td>\n",
       "      <td>due copyright restrictions authorized display ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   SongID                    Song_x  \\\n",
       "0               '65 Love AffairPaul Davis           '65 Love Affair   \n",
       "1  'Til My Baby Comes HomeLuther Vandross   'Til My Baby Comes Home   \n",
       "2     'Til Summer Comes AroundKeith Urban  'Til Summer Comes Around   \n",
       "3             'Til You Do Me RightAfter 7      'Til You Do Me Right   \n",
       "4                          'TilThe Angels                      'Til   \n",
       "\n",
       "       Performer_x                                           Lyrics_x  Hit_x  \\\n",
       "0       Paul Davis  I was a car hop\\rYou were into be-bop\\rYou san...  False   \n",
       "1  Luther Vandross  Theres a whole lot of girls\\r\\nmessin around\\r...  False   \n",
       "2      Keith Urban  Another long summer's come and gone\\r\\nI don't...  False   \n",
       "3          After 7  I was in love with you\\r\\nAnd gave my heart to...  False   \n",
       "4       The Angels  Due to copyright restrictions, we are not auth...  False   \n",
       "\n",
       "                                      Cleaned_Lyrics  \n",
       "0  car hop bebop sang wop diddy wop diddy wop doo...  \n",
       "1  whole lot girls messin around trying get thing...  \n",
       "2  another long summer 's come gone know always e...  \n",
       "3  love gave heart best keep satisfied took love ...  \n",
       "4  due copyright restrictions authorized display ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdec298b-6e48-4565-a795-8db74bf3c38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SongID', 'Song_x', 'Performer_x', 'Lyrics_x', 'Hit_x',\n",
       "       'Cleaned_Lyrics'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d46133-8fe0-47d8-9fcc-0dfb597da235",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {\"Song_x\" : \"Song\", \"Performer_x\" : \"Performer\", \"Lyrics_x\" : \"Lyrics\", \"Hit_x\" : \"Hit\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad701921-5a07-4aa7-a58f-4e019bfd1fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SongID</th>\n",
       "      <th>Song</th>\n",
       "      <th>Performer</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Hit</th>\n",
       "      <th>Cleaned_Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'65 Love AffairPaul Davis</td>\n",
       "      <td>'65 Love Affair</td>\n",
       "      <td>Paul Davis</td>\n",
       "      <td>I was a car hop\\rYou were into be-bop\\rYou san...</td>\n",
       "      <td>False</td>\n",
       "      <td>car hop bebop sang wop diddy wop diddy wop doo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Til My Baby Comes HomeLuther Vandross</td>\n",
       "      <td>'Til My Baby Comes Home</td>\n",
       "      <td>Luther Vandross</td>\n",
       "      <td>Theres a whole lot of girls\\r\\nmessin around\\r...</td>\n",
       "      <td>False</td>\n",
       "      <td>whole lot girls messin around trying get thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'Til Summer Comes AroundKeith Urban</td>\n",
       "      <td>'Til Summer Comes Around</td>\n",
       "      <td>Keith Urban</td>\n",
       "      <td>Another long summer's come and gone\\r\\nI don't...</td>\n",
       "      <td>False</td>\n",
       "      <td>another long summer 's come gone know always e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Til You Do Me RightAfter 7</td>\n",
       "      <td>'Til You Do Me Right</td>\n",
       "      <td>After 7</td>\n",
       "      <td>I was in love with you\\r\\nAnd gave my heart to...</td>\n",
       "      <td>False</td>\n",
       "      <td>love gave heart best keep satisfied took love ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'TilThe Angels</td>\n",
       "      <td>'Til</td>\n",
       "      <td>The Angels</td>\n",
       "      <td>Due to copyright restrictions, we are not auth...</td>\n",
       "      <td>False</td>\n",
       "      <td>due copyright restrictions authorized display ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   SongID                      Song  \\\n",
       "0               '65 Love AffairPaul Davis           '65 Love Affair   \n",
       "1  'Til My Baby Comes HomeLuther Vandross   'Til My Baby Comes Home   \n",
       "2     'Til Summer Comes AroundKeith Urban  'Til Summer Comes Around   \n",
       "3             'Til You Do Me RightAfter 7      'Til You Do Me Right   \n",
       "4                          'TilThe Angels                      'Til   \n",
       "\n",
       "         Performer                                             Lyrics    Hit  \\\n",
       "0       Paul Davis  I was a car hop\\rYou were into be-bop\\rYou san...  False   \n",
       "1  Luther Vandross  Theres a whole lot of girls\\r\\nmessin around\\r...  False   \n",
       "2      Keith Urban  Another long summer's come and gone\\r\\nI don't...  False   \n",
       "3          After 7  I was in love with you\\r\\nAnd gave my heart to...  False   \n",
       "4       The Angels  Due to copyright restrictions, we are not auth...  False   \n",
       "\n",
       "                                      Cleaned_Lyrics  \n",
       "0  car hop bebop sang wop diddy wop diddy wop doo...  \n",
       "1  whole lot girls messin around trying get thing...  \n",
       "2  another long summer 's come gone know always e...  \n",
       "3  love gave heart best keep satisfied took love ...  \n",
       "4  due copyright restrictions authorized display ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eefcfe1-6088-4af7-b08c-d77b03fd434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Hit\"] = df[\"Hit\"].astype('int') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd6092-7895-4a17-b2eb-c90ea849060b",
   "metadata": {},
   "source": [
    "# Handling Class Imblaance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9ed5b96-a0ac-42bd-9716-7fe52bc21721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "723f1cd8-9f28-4033-9772-b9607a43d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Cleaned_Lyrics']  # Features (lyrics)\n",
    "y = df['Hit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5643a03f-0791-4153-9f9c-852b07ea4fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fd74dee-42f2-4ad2-a1d7-3fb7f4dec627",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = undersampler.fit_resample(X.values.reshape(-1, 1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97930656-833f-4c5c-8e93-631b3bf40b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled dataset shape: hit\n",
      "0    4915\n",
      "1    4915\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_resampled = pd.DataFrame({'cleaned_lyrics': X_resampled.flatten(), 'hit': y_resampled})\n",
    "print(f\"Resampled dataset shape: {df_resampled['hit'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f85a8a9-d0c9-421b-89bb-e589e21eb05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_lyrics</th>\n",
       "      <th>hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>starry eyed came running arms cried let go kne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jesus loves little children little children wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free know price pay could lover life leads thr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neighbor carl lives next door pink flamingos p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>every day see face crack smile talk try take p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cleaned_lyrics  hit\n",
       "0  starry eyed came running arms cried let go kne...    0\n",
       "1  jesus loves little children little children wo...    0\n",
       "2  free know price pay could lover life leads thr...    0\n",
       "3  neighbor carl lives next door pink flamingos p...    0\n",
       "4  every day see face crack smile talk try take p...    0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088952a4-6cf9-4db0-91e9-c969c9fc4d11",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6a04cce-bf60-4bf9-923b-40de21f549b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 04:19:05.475786: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3ffe847-0660-47e0-9ece-a37f6204046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cb5dfec-c128-42ef-8fbb-2e4f39ffd9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-16 15:26:28.331146: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ebd387e-eca0-4807-8c58-b3d3b449cdc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_lyrics</th>\n",
       "      <th>hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>starry eyed came running arms cried let go kne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jesus loves little children little children wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free know price pay could lover life leads thr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neighbor carl lives next door pink flamingos p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>every day see face crack smile talk try take p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cleaned_lyrics  hit\n",
       "0  starry eyed came running arms cried let go kne...    0\n",
       "1  jesus loves little children little children wo...    0\n",
       "2  free know price pay could lover life leads thr...    0\n",
       "3  neighbor carl lives next door pink flamingos p...    0\n",
       "4  every day see face crack smile talk try take p...    0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3aabab85-e343-4511-814f-7f3d68907fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9830 entries, 0 to 9829\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   cleaned_lyrics  9818 non-null   object\n",
      " 1   hit             9830 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 153.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_resampled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2bb4c86-99d7-44ae-8772-3461e1ef311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled[\"cleaned_lyrics\"] = df_resampled[\"cleaned_lyrics\"].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29f105a8-c2ea-4950-a744-1d2933a91b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_lyrics</th>\n",
       "      <th>hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>starry eyed came running arms cried let go kne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jesus loves little children little children wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free know price pay could lover life leads thr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neighbor carl lives next door pink flamingos p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>every day see face crack smile talk try take p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cleaned_lyrics  hit\n",
       "0  starry eyed came running arms cried let go kne...    0\n",
       "1  jesus loves little children little children wo...    0\n",
       "2  free know price pay could lover life leads thr...    0\n",
       "3  neighbor carl lives next door pink flamingos p...    0\n",
       "4  every day see face crack smile talk try take p...    0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c3353075-4179-4f52-b66e-6c9fa111153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_resampled['cleaned_lyrics'])\n",
    "X_tokenized = tokenizer.texts_to_sequences(df_resampled['cleaned_lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "164fb41b-c11b-4fed-bc63-765de11cd9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [text.split() for text in df_resampled['cleaned_lyrics']]\n",
    "\n",
    "# 2. Create Word2Vec Embedding Matrix\n",
    "word2vec_model = Word2Vec(sentences=sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "700042d9-8d7e-47ca-8f5b-9fc3b1d57084",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, index in tokenizer.word_index.items():\n",
    "    if word in word2vec_model.wv:\n",
    "        embedding_matrix[index] = word2vec_model.wv[word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70572458-ba03-416b-a59a-84b9c0d77767",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "X_padded = pad_sequences(X_tokenized, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3f57dbc2-9d45-4a0b-9cdd-d5ab9e109dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_resampled[\"hit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b89e9a72-be75-40c5-bea3-0108d0e8f079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GlobalAveragePooling1D\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b26de0eb-bd67-4233-8eb4-454e1430e408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,284,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │     \u001b[38;5;34m4,284,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,284,100</span> (16.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,284,100\u001b[0m (16.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,284,100</span> (16.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,284,100\u001b[0m (16.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1,\n",
    "                    output_dim=100,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_len,\n",
    "                    trainable=False))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7fff7a78-396e-4d63-ac6a-4ccb8fb14b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8979d826-6ad3-4682-acea-a19a0122916f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - accuracy: 0.6148 - loss: 0.6427 - val_accuracy: 0.6586 - val_loss: 0.6227\n",
      "Epoch 2/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 75ms/step - accuracy: 0.6433 - loss: 0.6302 - val_accuracy: 0.6510 - val_loss: 0.6310\n",
      "Epoch 3/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.6471 - loss: 0.6248 - val_accuracy: 0.6580 - val_loss: 0.6277\n",
      "Epoch 4/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - accuracy: 0.6445 - loss: 0.6280 - val_accuracy: 0.6554 - val_loss: 0.6240\n",
      "Epoch 5/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - accuracy: 0.6448 - loss: 0.6265 - val_accuracy: 0.6643 - val_loss: 0.6221\n",
      "Epoch 6/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.6535 - loss: 0.6220 - val_accuracy: 0.6484 - val_loss: 0.6310\n",
      "Epoch 7/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 74ms/step - accuracy: 0.6582 - loss: 0.6159 - val_accuracy: 0.6567 - val_loss: 0.6296\n",
      "Epoch 8/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 75ms/step - accuracy: 0.6578 - loss: 0.6157 - val_accuracy: 0.6535 - val_loss: 0.6316\n",
      "Epoch 9/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.6754 - loss: 0.6019 - val_accuracy: 0.6453 - val_loss: 0.6376\n",
      "Epoch 10/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 87ms/step - accuracy: 0.6781 - loss: 0.6048 - val_accuracy: 0.6497 - val_loss: 0.6275\n",
      "Epoch 11/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 85ms/step - accuracy: 0.6843 - loss: 0.5959 - val_accuracy: 0.6472 - val_loss: 0.6406\n",
      "Epoch 12/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.6919 - loss: 0.5774 - val_accuracy: 0.6160 - val_loss: 0.6842\n",
      "Epoch 13/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 82ms/step - accuracy: 0.6924 - loss: 0.5730 - val_accuracy: 0.6453 - val_loss: 0.6364\n",
      "Epoch 14/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 82ms/step - accuracy: 0.7083 - loss: 0.5573 - val_accuracy: 0.6338 - val_loss: 0.6494\n",
      "Epoch 15/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.7191 - loss: 0.5486 - val_accuracy: 0.6478 - val_loss: 0.6502\n",
      "Epoch 16/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 82ms/step - accuracy: 0.7122 - loss: 0.5516 - val_accuracy: 0.6478 - val_loss: 0.6566\n",
      "Epoch 17/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.7295 - loss: 0.5435 - val_accuracy: 0.6408 - val_loss: 0.6589\n",
      "Epoch 18/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 84ms/step - accuracy: 0.7491 - loss: 0.5217 - val_accuracy: 0.6325 - val_loss: 0.6768\n",
      "Epoch 19/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 91ms/step - accuracy: 0.7345 - loss: 0.5230 - val_accuracy: 0.6459 - val_loss: 0.6730\n",
      "Epoch 20/20\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.7641 - loss: 0.4950 - val_accuracy: 0.6262 - val_loss: 0.6974\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6133054d-1ee2-4ba8-bce8-0a70599e40e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GlobalAveragePooling1D\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8d638eab-b84f-4f7c-9f3c-a6c6056f8f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int) #convert probabilities to binary predictions\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a45a5a9e-f989-4bc0-8cc5-722ee7482b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6409\n",
      "Precision: 0.6313\n",
      "Recall: 0.6560\n",
      "F1-score: 0.6434\n",
      "ROC AUC: 0.6906\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "181c2797-3919-4b63-83f4-53533295f91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "83d50baa-d44b-4d47-a944-a427a452d9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lyrics_tokenizer.pkl']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('lyrics_model.h5')\n",
    "word2vec_model.save('lyrics_word2vec.model')\n",
    "joblib.dump(tokenizer, 'lyrics_tokenizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693be92e-4e3d-4425-8a26-1fc4770febda",
   "metadata": {},
   "source": [
    "# Input for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "57005483-9caf-41d8-a435-c1003cd4d51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to compute the average Word2Vec vector for a given song's lyrics\n",
    "def average_word_vectors(sequences, embedding_matrix, embedding_dim):\n",
    "    features = []\n",
    "    for seq in sequences:\n",
    "        word_vectors = [embedding_matrix[idx] for idx in seq if idx < len(embedding_matrix)]\n",
    "        if len(word_vectors) > 0:\n",
    "            avg_vector = np.mean(word_vectors, axis=0)\n",
    "        else:\n",
    "            avg_vector = np.zeros(embedding_dim)  # Handle empty lyrics\n",
    "        features.append(avg_vector)\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2505285-cf0c-4934-9da2-eda562dbf13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = average_word_vectors(X_padded, embedding_matrix, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "20998d8e-88db-463d-904d-59255e588df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_resampled[\"hit\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cffcaf-b8bb-4676-850a-a2313c180025",
   "metadata": {},
   "source": [
    "# ML - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f0d409cb-87d4-4673-a030-df64c39ef893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0252bfcb-1d8c-417a-9be7-5d9bdc0083e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b03bdd40-8cdc-40c4-a2f4-30c01b87e1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.6052899287894201\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.60      0.61       995\n",
      "           1       0.60      0.61      0.60       971\n",
      "\n",
      "    accuracy                           0.61      1966\n",
      "   macro avg       0.61      0.61      0.61      1966\n",
      "weighted avg       0.61      0.61      0.61      1966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0320661c-9000-47e8-b336-f52617fa2293",
   "metadata": {},
   "source": [
    "# ML - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5a9f6d50-f31c-4869-b92d-4d625dcbef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a6e89d80-5873-4dae-8cfe-bae6d1b4c702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6236012207527976\n",
      "SVM Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.63       995\n",
      "           1       0.62      0.60      0.61       971\n",
      "\n",
      "    accuracy                           0.62      1966\n",
      "   macro avg       0.62      0.62      0.62      1966\n",
      "weighted avg       0.62      0.62      0.62      1966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"SVM Classification Report:\\n\", classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c142dc-3292-4963-9e92-cb8f5069ca0b",
   "metadata": {},
   "source": [
    "# ML - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3a18174c-2189-4398-a06d-36a9c2ca0c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [15:33:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.6108850457782299\n",
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.62      0.62       995\n",
      "           1       0.61      0.60      0.60       971\n",
      "\n",
      "    accuracy                           0.61      1966\n",
      "   macro avg       0.61      0.61      0.61      1966\n",
      "weighted avg       0.61      0.61      0.61      1966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"XGBoost Classification Report:\\n\", classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5146af33-63fd-4775-add7-8fc248232de7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
